## 一、准备 chart 包

1、下载
   
   https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack

2、修改 values.yaml
   
   ```diff
   211c242
   # 开启 alertmanager.ingress
   <     enabled: false
   ---
   >     enabled: true
   
   215c246
   <     # ingressClassName: nginx
   ---
   >     ingressClassName: nginx
   
   223,224c254,255
   <     hosts: []
   <       # - alertmanager.domain.com
   ---
   >     hosts: ["alertmanager.ava.com"]
   >      # - alertmanager.ava.com
   
   398c429
   <       repository: quay.io/prometheus/alertmanager
   ---
   >       repository: harbor.ava.com/ava/alertmanager
   
   510,512c541,544
   <     resources: {}
   <     # requests:
   <     #   memory: 400Mi
   ---
   >     resources: # {}
   >       requests:
   >         memory: 400Mi
   >         cpu: 500m
   
   641c673
   <   defaultDashboardsTimezone: utc
   ---
   >   defaultDashboardsTimezone: cst
   
   648c680
   # 开启grafana
   <     enabled: false
   ---
   >     enabled: true
   
   652c684,686
   <     annotations: {}
   ---
   >     annotations: {
   >       "kubernetes.io/ingress.class": "nginx"
   > }
   
   665c699
   <     hosts: []
   ---
   >     hosts: ["grafana.ava.com"]
   
   1091,1092c1125,1126
   # 修改etcd的监控端口
   <     port: 2379
   <     targetPort: 2379
   ---
   >     port: 2381 #2379
   >     targetPort: 2381 #2379
   
   1383c1417
   <         repository: k8s.gcr.io/ingress-nginx/kube-webhook-certgen
   ---
   >         repository: harbor.ava.com/ava/kube-webhook-certgen
   
   1385c1419
   <         sha: "f3b6b39a6062328c095337b4cadcefd1612348fdd5190b1dcbcb9b9e90bd8068"
   ---
   > #        sha: "f3b6b39a6062328c095337b4cadcefd1612348fdd5190b1dcbcb9b9e90bd8068"
   
   1532,1538c1566,1572
   <   resources: {}
   <   # limits:
   <   #   cpu: 200m
   <   #   memory: 200Mi
   <   # requests:
   <   #   cpu: 100m
   <   #   memory: 100Mi
   ---
   >   resources: #{}
   >     limits:
   >       cpu: 200m
   >       memory: 200Mi
   >     requests:
   >       cpu: 100m
   >       memory: 100Mi
   
   1591c1625
   <     repository: quay.io/prometheus-operator/prometheus-operator
   ---
   >     repository: harbor.ava.com/ava/prometheus-operator
   
   1607c1641
   <     repository: quay.io/prometheus-operator/prometheus-config-reloader
   ---
   >     repository: harbor.ava.com/ava/prometheus-config-reloader
   
   1613c1647
   <   configReloaderCpu: 100m
   ---
   >   configReloaderCpu: 1000m
   
   1617c1651
   <   configReloaderMemory: 50Mi
   ---
   >   configReloaderMemory: 3000Mi
   
   1622c1656
   <     repository: quay.io/thanos/thanos
   ---
   >     repository: harbor.ava.com/ava/thanos
   
   1801c1835
   # 开启thanosIngress
   <     enabled: false
   ---
   >     enabled: true
   
   1805c1839
   <     # ingressClassName: nginx
   ---
   >     ingressClassName: nginx
   1818c1852
   <     hosts: []
   ---
   >     hosts: ["thanos-gateway.ava.com"]
   
   1851c1885
   # 开启 Prometheus的ingress
   <     enabled: false
   ---
   >     enabled: true
   
   1855c1889
   <     # ingressClassName: nginx
   ---
   >     ingressClassName: nginx
   
   1865c1899
   <     hosts: []
   ---
   >     hosts: ["prometheus.ava.com"]
   
   2015c2049
   <       repository: quay.io/prometheus/prometheus
   ---
   >       repository: harbor.ava.com/ava/prometheus
   
   2289,2291c2323,2326
   <     resources: {}
   <     # requests:
   <     #   memory: 400Mi
   ---
   > #    resources: {}
   >     requests:
   >       memory: 400Mi
   >       cpu: 500m
   ```

## 二、安装

```bash
helm install kube-prometheus-stack -n monitor . -f values.yaml
```

## 三、增加告警规则

1、在 values.yaml 中的 `additionalPrometheusRules`，修改如下：
   
   下面增加了对 pv 和 ceph 的监控规则
   
   > 注意：ceph 需求开启监控
   
   ```yaml
   additionalPrometheusRules:
     - name: disk
       groups:
         - name: disk
           rules:
           - alert: PVUsage
             expr:  kubelet_volume_stats_used_bytes/kubelet_volume_stats_capacity_bytes * 100 > 85
             for: 1m
             labels:
               team: ops
             annotations:
               summary: "cluster:{{ $labels.cluster }} {{ $labels.instance }}: High Disk usage detected"
               description: "{{ $labels.instance }}: Disk usage is above 85% (current value is: {{ $value }}"
   
     - name: ceph.rules
       groups:
       - name: ceph.rules
         rules:
         - alert: CephTargetDown
           expr: up{job="ceph"} == 0
           for: 10m
           labels:
             severity: critical
           annotations:
             description: CEPH target down for more than 2m, please check - it could be a either exporter crash or a whole cluster crash
             summary: CEPH exporter down
         - alert: CephErrorState
           expr: ceph_health_status > 1
           for: 5m
           labels:
             severity: critical
           annotations:
             description: Ceph is in Error state longer than 5m, please check status of pools and OSDs
             summary: CEPH in ERROR
         - alert: CephWarnState
           expr: ceph_health_status == 1
           for: 30m
           labels:
             severity: warning
           annotations:
             description: Ceph is in Warn state longer than 30m, please check status of pools and OSDs
             summary: CEPH in WARN
         - alert: OsdDown
           expr: ceph_osd_up == 0
           for: 30m
           labels:
             severity: warning
           annotations:
             description: OSD is down longer than 30 min, please check whats the status
             summary: OSD down
         - alert: OsdApplyLatencyTooHigh
           expr: ceph_osd_perf_apply_latency_seconds > 10
           for: 90s
           labels:
             severity: warning
           annotations:
             description: OSD latency for {{ $labels.osd }} is too high. Please check if it doesn't stuck in weird state
             summary: OSD latency too high {{ $labels.osd }}
         - alert: MonitorClockSkewTooHigh
           expr: abs(ceph_monitor_clock_skew_seconds) > 0.1
           for: 60s
           labels:
             severity: warning
           annotations:
             description: Monitor clock skew detected on  {{ $labels.monitor }} - please check ntp and harware clock settins
             summary: Clock skew detected on {{ $labels.monitor }}
         - alert: MonitorAvailableStorage
           expr: ceph_monitor_avail_percent < 30
           for: 60s
           labels:
             severity: warning
           annotations:
             description: Monitor storage for {{ $labels.monitor }} less than 30% - please check why its too high
             summary: Nonitor storage for  {{ $labels.monitor }} less than 30%
         - alert: MonitorAvailableStorage
           expr: ceph_monitor_avail_percent < 15
           for: 60s
           labels:
             severity: critical
           annotations:
             description: Monitor storage for {{ $labels.monitor }} less than 15% - please check why its too high
             summary: Nonitor storage for  {{ $labels.monitor }} less than 15%
         - alert: CephOSDUtilizatoin
           expr: ceph_osd_utilization > 90
           for: 60s
           labels:
             severity: critical
           annotations:
             description: Osd free space for  {{ $labels.osd }} is higher tan 90%. Please validate why its so big, reweight or add storage
             summary: OSD {{ $labels.osd }} is going out of space
         - alert: CephPgDown
           expr: ceph_pg_down > 0
           for: 3m
           labels:
             severity: critical
           annotations:
             description: Some groups are down (unavailable) for too long on {{ $labels.cluster }}. Please ensure that all the data are available
             summary: PG DOWN [{{ $value }}] on {{ $labels.cluster }}
         - alert: CephPgIncomplete
           expr: ceph_pg_incomplete > 0
           for: 2m
           labels:
             severity: critical
           annotations:
             description: Some groups are incomplete (unavailable) for too long on {{ $labels.cluster }}. Please ensure that all the data are available
             summary: PG INCOMPLETE [{{ $value }}] on {{ $labels.cluster }}
         - alert: CephPgInconsistent
           expr: ceph_pg_inconsistent > 0
           for: 1m
           labels:
             severity: warning
           annotations:
             description: Some groups are inconsistent for too long on {{ $labels.cluster }}. Data is available but inconsistent across nodes
             summary: PG INCONSISTENT [{{ $value }}] on {{ $labels.cluster }}
         - alert: CephPgActivating
           expr: ceph_pg_activating > 0
           for: 5m
           labels:
             severity: critical
           annotations:
             description: Some groups are activating for too long on {{ $labels.cluster }}. Those PGs are unavailable for too long!
             summary: PG ACTIVATING [{{ $value }}] on {{ $labels.cluster }}
         - alert: CephPgBackfillTooFull
           expr: ceph_pg_backfill_toofull > 0
           for: 5m
           labels:
             severity: warning
           annotations:
             description: Some groups are located on full OSD on cluster {{ $labels.cluster }}. Those PGs can be unavailable shortly. Please check OSDs, change weight or reconfigure CRUSH rules.
             summary: PG TOO FULL [{{ $value }}] on {{ $labels.cluster }}
         - alert: CephPgUnavailable
           expr: ceph_pg_total - ceph_pg_active > 0
           for: 5m
           labels:
             severity: critical
           annotations:
             description: Some groups are unavailable on {{ $labels.cluster }}. Please check their detailed status and current configuration.
             summary: PG UNAVAILABLE [{{ $value }}] on {{ $labels.cluster }}
         - alert: CephOsdReweighted
           expr: ceph_osd_weight < 1
           for: 1h
           labels:
             severity: warning
           annotations:
             description: OSD {{ $labels.ceph_daemon}} on cluster {{ $labels.cluster}} was reweighted for too long. Please either create silent or fix that issue
             summary: OSD {{ $labels.ceph_daemon }} on {{ $labels.cluster }} reweighted - {{ $value }}
   ```

## 四、配置邮件通知

这里以 126 邮箱为例，前提是能够访问 smtp.126.com 的 25 端口。

在 values.yaml 中的 `alertmanager` 下面的 `config`，修改如下：

```yaml
config:
    global:
      resolve_timeout: 5m
      smtp_smarthost: 'smtp.126.com:25'
      smtp_from: 'kaifa5s@126.com'
      smtp_auth_username: 'kaifa5s@126.com'
      smtp_auth_password: 'LWZSGGTYXMVFWQBW' # 这里是邮箱的授权码
      smtp_require_tls: false
    templates:
      - '/alertmanager/template/*.tmpl'
    route:
      #group_by: ['alertname', 'cluster', 'service']
      group_by: ['instance']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 10m
      receiver: default-receiver
      routes:
        - match_re:
            team: "ops"
          receiver: webhook
    receivers:
    - name: 'default-receiver'
      email_configs:
      - to: 'kaifa5ss@126.com'
      - to: 'example@test.com'
    - name: 'webhook'
      webhook_configs:
      - url: 'http://example.test.com'
```

## 五、监控基础服务

这里以 mysql 为例。

1、获取 chart 包
   
   ```bash
   helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
   helm repo update
   helm pull prometheus-community/prometheus-mysql-exporter
   ```

2、修改 values.yaml 文件
   
   ```diff
   8c8
   <   repository: "prom/mysqld-exporter"
   ---
   >   repository: "harbor.ava.com/ava/mysqld-exporter"
   
   14c14,15
   <   annotations: {}
   ---
   >   annotations: # {}
   >     prometheus.io/scrape: "true"
   
   29c30
   <   jobLabel: ""
   ---
   >   jobLabel: "mysql-exporter"
   
   78,113c79,114
   < collectors: {}
   <   # auto_increment.columns: false
   <   # binlog_size: false
   <   # engine_innodb_status: false
   <   # engine_tokudb_status: false
   <   # global_status: true
   <   # global_variables: true
   <   # info_schema.clientstats: false
   <   # info_schema.innodb_metrics: false
   <   # info_schema.innodb_tablespaces: false
   <   # info_schema.innodb_cmp: false
   <   # info_schema.innodb_cmpmem: false
   <   # info_schema.processlist: false
   <   # info_schema.processlist.min_time: 0
   <   # info_schema.query_response_time: false
   <   # info_schema.tables: true
   <   # info_schema.tables.databases: '*'
   <   # info_schema.tablestats: false
   <   # info_schema.schemastats: false
   <   # info_schema.userstats: false
   <   # perf_schema.eventsstatements: false
   <   # perf_schema.eventsstatements.digest_text_limit: 120
   <   # perf_schema.eventsstatements.limit: false
   <   # perf_schema.eventsstatements.timelimit: 86400
   <   # perf_schema.eventswaits: false
   <   # perf_schema.file_events: false
   <   # perf_schema.file_instances: false
   <   # perf_schema.indexiowaits: false
   <   # perf_schema.tableiowaits: false
   <   # perf_schema.tablelocks: false
   <   # perf_schema.replication_group_member_stats: false
   <   # slave_status: true
   <   # slave_hosts: false
   <   # heartbeat: false
   <   # heartbeat.database: heartbeat
   <   # heartbeat.table: heartbeat
   ---
   > collectors: # {}
   >   auto_increment.columns: false
   >   binlog_size: false
   >   engine_innodb_status: false
   >   engine_tokudb_status: false
   >   global_status: true
   >   global_variables: true
   >   info_schema.clientstats: false
   >   info_schema.innodb_metrics: false
   >   info_schema.innodb_tablespaces: false
   >   info_schema.innodb_cmp: false
   >   info_schema.innodb_cmpmem: false
   >   info_schema.processlist: false
   >   info_schema.processlist.min_time: 0
   >   info_schema.query_response_time: false
   >   info_schema.tables: true
   >   info_schema.tables.databases: '*'
   >   info_schema.tablestats: false
   >   info_schema.schemastats: false
   >   info_schema.userstats: false
   >   perf_schema.eventsstatements: false
   >   perf_schema.eventsstatements.digest_text_limit: 120
   >   perf_schema.eventsstatements.limit: 250
   >   perf_schema.eventsstatements.timelimit: 86400
   >   perf_schema.eventswaits: false
   >   perf_schema.file_events: false
   >   perf_schema.file_instances: false
   >   perf_schema.indexiowaits: false
   >   perf_schema.tableiowaits: false
   >   perf_schema.tablelocks: false
   >   perf_schema.replication_group_member_stats: false
   >   slave_status: true
   >   slave_hosts: false
   >   heartbeat: false
   >   heartbeat.database: heartbeat
   >   heartbeat.table: heartbeat
   
   118c119
   <   host: "localhost"
   ---
   >   host: "mysql-master-svc.basic-service"
   
   120c121
   <   pass: "password"
   ---
   >   pass: "dzsw@2020#$%^"
   
   123c124
   <   user: "exporter"
   ---
   >   user: "root"
   ```

3、在 kube-prometheus-stack chart 包下面的 values.yaml 文件中找到 `additionalServiceMonitors`
   
   ```diff
   2508c2597,2651
   <   additionalServiceMonitors: []
   ---
   >   additionalServiceMonitors: 
   >   - name: "mysql-exporter"
   >     jobLabel: "mysql-exporter"
   >     selector:
   >       matchLabels:
   >         app: prometheus-mysql-exporter
   >         release: prometheus-mysql-exporter
   >     namespaceSelector:
   >       matchNames: ["monitor"]
   >     endpoints:
   >       - port: mysql-exporter
   ```

4、检查
   
   打开 prometheus web 页面，查看 target 中是否新增了刚才添加的 mysql-export

5、其他基础服务
   
   * prometheus-community/prometheus-redis-exporter
   * prometheus-community/prometheus-elasticsearch-exporter
   * prometheus-community/prometheus-kafka-exporter
   * prometheus-community/prometheus-rabbitmq-exporter
   * ......